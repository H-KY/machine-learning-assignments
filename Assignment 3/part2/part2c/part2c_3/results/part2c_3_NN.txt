NUMBER OF HIDDEN LAYERS = 1
NUMBER OF NEURONS IN THE HIDDEN LAYER = 100

USING COST FUNCTION AS THE STOPPING CRITERIA:

LEARNING RATE = 26.6
ACTIVATION FUNCTION IN HIDDEN LAYER = SIGMOID
ACTIVATION FUNCTION IN THE OUTPUT LAYER = SIGMOID
EPSILON = 10 ^ (-6)
NUMBER OF ITERATIONS TAKEN : 2635
TRAINGING ACCURACY : 99.7
TESTING ACCURACY : 99.3055555556

LEARNING RATE = 1
RIGHT SUBGRADIENT WAS TAKEN IN THIS CASE.
ACTIVATION FUNCTION IN HIDDEN LAYER = ReLU
ACTIVATION FUNCTION IN THE OUTPUT LAYER = SIGMOID
EPSILON = 10 ^ (-6)
NUMBER OF ITERATIONS TAKEN : 3193
TRAINGING ACCURACY : 98.58
TESTING ACCURACY : 98.5833333333


WHEN VALIDATION SET WAS USED :

RELU CASE:
LEARNING RATE : 150
RIGHT SUBGRADIENT IS USED.
EPSILON = 10^(-8)
NUMBER OF ITERATIONS TAKEN : 7
TRAINGING ACCURACY : 96.43
TESTING ACCURACY : 96.6111111111

SIGMOID:
LEARNING RATE : 47.2
NUMBER OF ITERATIONS TAKEN : 3
TRAINGING ACCURACY : 81.03
TESTING ACCURACY : 79.9444444444


WHEN THE BOUND ON THE NUMBER OF EPOCHS WAS USED :

RELU:
NUMBER OF EPOCHS = 200
LEARNING RATE = 15
NUMBER OF ITERATIONS TAKEN : 201
TRAINGING ACCURACY : 98.4
TESTING ACCURACY : 98.3333333333

NUMBER OF EPOCHS = 2635
LEARNING RATE = 15
NUMBER OF ITERATIONS TAKEN : 2636
TRAINGING ACCURACY : 99.66
TESTING ACCURACY : 99.1388888889

SIGMOID:
NUMBER OF ITERATIONS TAKEN : 201
TRAINGING ACCURACY : 99.19
TESTING ACCURACY : 99.0555555556

ACTIVATION FUNCTION IN HIDDEN LAYER = SIGMOID
ACTIVATION FUNCTION IN THE OUTPUT LAYER = SIGMOID
EPSILON = 10 ^ (-6)
NUMBER OF ITERATIONS TAKEN : 2635
TRAINGING ACCURACY : 99.7
TESTING ACCURACY : 99.3055555556



FINAL
SIGMOID	
NUMBER OF ITERATIONS TAKEN : 160
TRAINGING ACCURACY : 99.14
TESTING ACCURACY : 98.8888888889


NUMBER OF ITERATIONS TAKEN : 140
TRAINGING ACCURACY : 98.62
TESTING ACCURACY : 98.6111111111

